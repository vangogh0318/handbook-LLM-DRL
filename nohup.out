+ python ./rloo.py --config recipes/Qwen2.5-0.5B-Instruct/rloo/config_demo_accreward_simpledata.yaml
2025-04-27 10:22:15 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False
2025-04-27 10:22:15 - INFO - __main__ - Model parameters ModelConfig(model_name_or_path='model/Qwen2.5-0.5B-Instruct', model_revision='main', torch_dtype='bfloat16', trust_remote_code=True, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, use_dora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)
2025-04-27 10:22:15 - INFO - __main__ - Script parameters GRPOScriptArguments(dataset_name='datasets/SimpleRL-Zoo-Data', dataset_config='default', dataset_train_split='train', dataset_test_split='test', gradient_checkpointing_use_reentrant=False, ignore_bias_buffers=False, reward_funcs=['accuracy'], cosine_min_value_wrong=0.0, cosine_max_value_wrong=-0.5, cosine_min_value_correct=0.5, cosine_max_value_correct=1.0, cosine_max_len=1000, repetition_n_grams=3, repetition_max_penalty=-1.0, code_language='python', code_eval_test_batch_size=1, parallel_code_exec_per_proc=2, dataset_prompt_column='problem', e2b_router_url=None)
2025-04-27 10:22:15 - INFO - __main__ - Training parameters RLOOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
batch_size=None,
bf16=True,
bf16_full_eval=False,
chat_template=None,
cliprange=0.2,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
dataset_num_proc=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
ds3_gather_for_generation=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
exp_name=rloo_config,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kl_coef=0.0001,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_batch_size=None,
local_mini_batch_size=None,
local_rank=0,
local_rollout_forward_batch_size=64,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model/Qwen2.5-0.5B-simpleRL-rloo/runs/Apr27_10-22-15_autodl-container-2f3a4fb124-5c7c4683,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.COSINE,
max_completion_length=1024,
max_grad_norm=1.0,
max_prompt_length=512,
max_steps=-1,
metric_for_best_model=None,
micro_batch_size=None,
min_p=None,
mini_batch_size=None,
missing_eos_penalty=1,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
normalize_advantage=True,
normalize_reward=True,
num_mini_batches=2,
num_ppo_epochs=2,
num_sample_generations=10,
num_total_batches=None,
num_train_epochs=1,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=model/Qwen2.5-0.5B-simpleRL-rloo,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=16,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
repetition_penalty=1.0,
report_to=['tensorboard'],
response_length=1024,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
reward_clip_range=10.0,
reward_model_path=EleutherAI/pythia-160m,
rloo_k=4,
run_name=model/Qwen2.5-0.5B-simpleRL-rloo,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=10,
save_strategy=SaveStrategy.STEPS,
save_total_limit=30,
seed=42,
sft_model_path=EleutherAI/pythia-160m,
skip_memory_metrics=True,
stop_token=<STOP_TOKEN>,
stop_token_id=None,
system_prompt=You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>
...
</think>
<answer>
...
</answer>,
temperature=1,
tf32=None,
token_level_kl=False,
top_k=50,
top_p=1.0,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
total_episodes=None,
tp_size=0,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.1,
warmup_steps=0,
weight_decay=0.0,
whiten_rewards=False,
world_size=None,
)
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2058] 2025-04-27 10:22:15,936 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2323] 2025-04-27 10:22:16,194 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:691] 2025-04-27 10:22:16,195 >> loading configuration file model/Qwen2.5-0.5B-Instruct/config.json
[INFO|configuration_utils.py:765] 2025-04-27 10:22:16,196 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 896,
  "initializer_range": 0.02,
  "intermediate_size": 4864,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 14,
  "num_hidden_layers": 24,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:1121] 2025-04-27 10:22:16,238 >> loading weights file model/Qwen2.5-0.5B-Instruct/model.safetensors
[INFO|configuration_utils.py:1142] 2025-04-27 10:22:16,240 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "use_cache": false
}

[WARNING|logging.py:328] 2025-04-27 10:22:16,243 >> Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
[INFO|modeling_utils.py:4926] 2025-04-27 10:22:16,482 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4934] 2025-04-27 10:22:16,482 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at model/Qwen2.5-0.5B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1095] 2025-04-27 10:22:16,484 >> loading configuration file model/Qwen2.5-0.5B-Instruct/generation_config.json
[INFO|configuration_utils.py:1142] 2025-04-27 10:22:16,484 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.1,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|configuration_utils.py:691] 2025-04-27 10:22:16,485 >> loading configuration file model/Qwen2.5-0.5B-Instruct/config.json
[INFO|configuration_utils.py:765] 2025-04-27 10:22:16,485 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 896,
  "initializer_range": 0.02,
  "intermediate_size": 4864,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 14,
  "num_hidden_layers": 24,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:1121] 2025-04-27 10:22:16,486 >> loading weights file model/Qwen2.5-0.5B-Instruct/model.safetensors
[INFO|configuration_utils.py:1142] 2025-04-27 10:22:16,487 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "use_cache": false
}

[INFO|modeling_utils.py:4926] 2025-04-27 10:22:16,729 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4934] 2025-04-27 10:22:16,729 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at model/Qwen2.5-0.5B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1095] 2025-04-27 10:22:16,731 >> loading configuration file model/Qwen2.5-0.5B-Instruct/generation_config.json
[INFO|configuration_utils.py:1142] 2025-04-27 10:22:16,731 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.1,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

Using custom data configuration default-9510787fb66ff491
GRPOScriptArguments(dataset_name='datasets/SimpleRL-Zoo-Data', dataset_config='default', dataset_train_split='train', dataset_test_split='test', gradient_checkpointing_use_reentrant=False, ignore_bias_buffers=False, reward_funcs=['accuracy'], cosine_min_value_wrong=0.0, cosine_max_value_wrong=-0.5, cosine_min_value_correct=0.5, cosine_max_value_correct=1.0, cosine_max_len=1000, repetition_n_grams=3, repetition_max_penalty=-1.0, code_language='python', code_eval_test_batch_size=1, parallel_code_exec_per_proc=2, dataset_prompt_column='problem', e2b_router_url=None)
2025-04-27 10:22:17 - INFO - datasets.builder - Using custom data configuration default-9510787fb66ff491
Loading Dataset Infos from /root/miniconda3/envs/openr1/lib/python3.11/site-packages/datasets/packaged_modules/parquet
2025-04-27 10:22:17 - INFO - datasets.info - Loading Dataset Infos from /root/miniconda3/envs/openr1/lib/python3.11/site-packages/datasets/packaged_modules/parquet
Overwrite dataset info from restored data version if exists.
2025-04-27 10:22:17 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d
2025-04-27 10:22:17 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d
Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d)
2025-04-27 10:22:17 - INFO - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d)
Loading Dataset info from /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d
2025-04-27 10:22:17 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d
DatasetDict({
    train: Dataset({
        features: ['solution', 'problem'],
        num_rows: 8139
    })
})
{'solution': '0', 'problem': 'Find the remainder when $$33818^2 + 33819^2 + 33820^2 + 33821^2 + 33822^2$$is divided by 17.'}
{'solution': '[-77,77]', 'problem': 'If $\\mathbf{a}$ and $\\mathbf{b}$ are vectors such that $\\|\\mathbf{a}\\| = 7$ and $\\|\\mathbf{b}\\| = 11$, then find all possible values of $\\mathbf{a} \\cdot \\mathbf{b}$.\n\nSubmit your answer in interval notation.'}
{'solution': '-37_8', 'problem': 'What is $35_8-74_8?$ Express your answer in base 8.'}
Map:   0%|          | 0/8139 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d/cache-3e142499c7b70a68.arrow
2025-04-27 10:22:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/default-9510787fb66ff491/0.0.0/9c460aabd2aa27d1496e5e38d2060760561f0ac2cd6a110134eefa5b3f153b8d/cache-3e142499c7b70a68.arrow
Map:  37%|███▋      | 3000/8139 [00:00<00:00, 28509.08 examples/s]Map:  74%|███████▎  | 6000/8139 [00:00<00:00, 28560.24 examples/s]Map: 100%|██████████| 8139/8139 [00:00<00:00, 28330.51 examples/s]
add prompt
add prompt
add prompt
{'solution': '0', 'problem': 'Find the remainder when $$33818^2 + 33819^2 + 33820^2 + 33821^2 + 33822^2$$is divided by 17.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'Find the remainder when $$33818^2 + 33819^2 + 33820^2 + 33821^2 + 33822^2$$is divided by 17.', 'role': 'user'}]}
{'solution': '[-77,77]', 'problem': 'If $\\mathbf{a}$ and $\\mathbf{b}$ are vectors such that $\\|\\mathbf{a}\\| = 7$ and $\\|\\mathbf{b}\\| = 11$, then find all possible values of $\\mathbf{a} \\cdot \\mathbf{b}$.\n\nSubmit your answer in interval notation.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'If $\\mathbf{a}$ and $\\mathbf{b}$ are vectors such that $\\|\\mathbf{a}\\| = 7$ and $\\|\\mathbf{b}\\| = 11$, then find all possible values of $\\mathbf{a} \\cdot \\mathbf{b}$.\n\nSubmit your answer in interval notation.', 'role': 'user'}]}
{'solution': '-37_8', 'problem': 'What is $35_8-74_8?$ Express your answer in base 8.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'What is $35_8-74_8?$ Express your answer in base 8.', 'role': 'user'}]}
after tokenizer
after tokenizer
after tokenizer
{'solution': '0', 'problem': 'Find the remainder when $$33818^2 + 33819^2 + 33820^2 + 33821^2 + 33822^2$$is divided by 17.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'Find the remainder when $$33818^2 + 33819^2 + 33820^2 + 33821^2 + 33822^2$$is divided by 17.', 'role': 'user'}]}
{'solution': '[-77,77]', 'problem': 'If $\\mathbf{a}$ and $\\mathbf{b}$ are vectors such that $\\|\\mathbf{a}\\| = 7$ and $\\|\\mathbf{b}\\| = 11$, then find all possible values of $\\mathbf{a} \\cdot \\mathbf{b}$.\n\nSubmit your answer in interval notation.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'If $\\mathbf{a}$ and $\\mathbf{b}$ are vectors such that $\\|\\mathbf{a}\\| = 7$ and $\\|\\mathbf{b}\\| = 11$, then find all possible values of $\\mathbf{a} \\cdot \\mathbf{b}$.\n\nSubmit your answer in interval notation.', 'role': 'user'}]}
{'solution': '-37_8', 'problem': 'What is $35_8-74_8?$ Express your answer in base 8.', 'prompt': [{'content': 'You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n...\n</think>\n<answer>\n...\n</answer>', 'role': 'system'}, {'content': 'What is $35_8-74_8?$ Express your answer in base 8.', 'role': 'user'}]}
2025-04-27 10:22:17 - INFO - __main__ - *** Initializing model kwargs ***
2025-04-27 10:22:17 - WARNING - accelerate.utils.other - Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-04-27 10:22:18 - INFO - __main__ - *** Train ***
===training policy===
  0%|          | 0/16 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/root/autodl-tmp/github/open-r1/./rloo.py", line 286, in <module>
    main(script_args, training_args, model_args)
  File "/root/autodl-tmp/github/open-r1/./rloo.py", line 240, in main
    train_result = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/github/open-r1/src/open_r1/trainer/rloo_trainer.py", line 320, in train
    if self.max_prompt_length is not None:
       ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RLOOTrainer' object has no attribute 'max_prompt_length'
  0%|          | 0/16 [00:00<?, ?it/s]
